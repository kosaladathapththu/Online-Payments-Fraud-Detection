<div align="center">

# ğŸ›¡ï¸ Online Payments Fraud Detection

![Python](https://img.shields.io/badge/Python-3.x-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-ML-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![SMOTE](https://img.shields.io/badge/SMOTE-Class%20Balancing-6DB33F?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Complete-brightgreen?style=for-the-badge)

> **Detecting fraudulent online transactions using Machine Learning â€” with class balancing via SMOTE and ensemble classification.**

</div>

---

## ğŸ“Œ Project Overview

Online payment fraud is one of the most critical challenges in digital finance. This project builds a robust machine learning pipeline to **identify fraudulent transactions** from a large, highly imbalanced dataset using supervised learning techniques.

The core challenge â€” extreme class imbalance â€” was addressed using **SMOTE (Synthetic Minority Oversampling Technique)**, applied exclusively on training data to prevent data leakage.

---

## ğŸ“Š Dataset Information

| Property | Details |
|---|---|
| **Total Samples** | 200,000 |
| **Target Column** | `isFraud` |
| **Class `0`** | âœ… Not Fraud |
| **Class `1`** | ğŸš¨ Fraud |
| **Train Split** | 80% |
| **Test Split** | 20% |
| **Imbalance Handling** | SMOTE on training data only |

---

## âš™ï¸ Data Preprocessing

- âœ”ï¸ Removed duplicate records
- âœ”ï¸ Checked and handled missing values
- âœ”ï¸ Applied **SMOTE** to balance minority class in training set
- âœ”ï¸ Feature scaling applied where necessary
- âœ”ï¸ Stratified train-test split to maintain class ratios

---

## ğŸ“‰ Class Balancing with SMOTE

SMOTE was applied **only to training data** to simulate real-world conditions and avoid leakage. The test set remained imbalanced.

**Before SMOTE:**

```
Class 0 (Not Fraud) : 159,786
Class 1 (Fraud)     :     214
```

**After SMOTE:**

```
Class 0 (Not Fraud) : 159,786
Class 1 (Fraud)     : 159,786  âœ… Balanced!
```

---

## ğŸ¤– Models Trained

Three classification models were trained and compared:

| Model | Notes |
|---|---|
| ğŸ“ˆ Logistic Regression | Baseline linear model |
| ğŸŒ¿ Decision Tree | Non-linear, interpretable |
| ğŸŒ² Random Forest | Ensemble method â€” best performer |

---

## ğŸ“ˆ Evaluation Metrics

Each model was evaluated using a comprehensive set of metrics:

- **Accuracy** â€” Overall correctness
- **Confusion Matrix** â€” True/False Positives & Negatives
- **Precision** â€” Correctness of fraud predictions
- **Recall** â€” Coverage of actual fraud cases
- **F1-Score** â€” Harmonic mean of precision & recall
- **ROC Curve** â€” True vs. False Positive Rate
- **Precision-Recall Curve** â€” Performance under imbalance
- **Learning Curve** â€” Overfitting/underfitting diagnostics
- **Threshold Tuning** â€” Optimal classification threshold

---

## ğŸ† Final Model â€” Regularized Random Forest

```
Accuracy : ~99%
Model    : RandomForestClassifier (Regularized)
```

Overfitting was reduced using the following hyperparameters:

```python
RandomForestClassifier(
    max_depth=...,
    min_samples_split=...,
    min_samples_leaf=...
)
```

> âœ… High accuracy with a strong balance between precision and recall â€” no major overfitting observed after regularization.

---

## ğŸ“Š Visualizations Included

| Visualization | Purpose |
|---|---|
| Class Distribution Graph | Visualize imbalance before/after SMOTE |
| Correlation Heatmap | Feature relationships |
| Boxplots | Outlier detection |
| ROC Curve | Model discrimination ability |
| Precision-Recall Curve | Performance under imbalance |
| Model Comparison Chart | Side-by-side evaluation |
| Learning Curve | Bias-variance diagnostics |

---

## ğŸ§  Key Findings

- ğŸŒ² **Random Forest** outperformed all other models
- ğŸ“Š **SMOTE** significantly improved minority class (fraud) recall
- âš–ï¸ Class 1 (Fraud) recall improved substantially after balancing
- ğŸ”§ Regularization effectively controlled overfitting
- ğŸš« No major overfitting observed in the final model

---

## ğŸ’¾ Model Saving

The final model is saved using `joblib` for easy deployment:

```python
import joblib
joblib.dump(model, "fraud_detection_model.pkl")

# Load later
model = joblib.load("fraud_detection_model.pkl")
```

---

## ğŸš€ How to Run

**1. Open the notebook in Google Colab**

**2. Install required libraries:**

```bash
pip install imbalanced-learn
```

**3. Run all cells in order** â€” preprocessing â†’ SMOTE â†’ training â†’ evaluation

---

## ğŸ“‚ Project Structure

```
Online_Payments_Fraud_Detection/
â”‚
â”œâ”€â”€ ğŸ““ Online_Payments_Fraud_Detection.ipynb   # Main notebook
â”œâ”€â”€ ğŸ¤– fraud_detection_model.pkl               # Saved model
â””â”€â”€ ğŸ“„ README.md                               # Project documentation
```

---

## ğŸ”® Future Improvements

- [ ] Hyperparameter tuning with **GridSearchCV** / **RandomizedSearchCV**
- [ ] Explore **XGBoost** and **LightGBM** for better performance
- [ ] Deploy model as an interactive app using **Streamlit**
- [ ] Build a **real-time fraud detection REST API**
- [ ] Experiment with **deep learning** approaches (e.g., autoencoders)

---

## ğŸ‘¨â€ğŸ’» Author

<div align="center">

**Your Name**
*Machine Learning Project â€” 2026*

</div>

---

<div align="center">

â­ **If you found this project helpful, please consider giving it a star!** â­

</div>
